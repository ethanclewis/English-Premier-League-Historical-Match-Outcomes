{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74a60444",
   "metadata": {},
   "source": [
    "# Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc81462",
   "metadata": {},
   "source": [
    "Notebook contains code to import, clean, transform, and export 23 individual data frames containing match data spanning the 00/01 to 22/23 English Premier League seasons.\n",
    "\n",
    "Data source: https://www.football-data.co.uk/englandm.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d08529de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "from datetime import datetime "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d8073b",
   "metadata": {},
   "source": [
    "# Create Individual Path Endings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37f6c4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = 00  # Change this to the desired start year\n",
    "end_year = 22  # Change this to the desired end year\n",
    "\n",
    "# Initialize an empty list to store the generated strings\n",
    "season_files = []\n",
    "\n",
    "# Loop to generate the strings\n",
    "for i in range(start_year, end_year + 1):\n",
    "    current_year = i\n",
    "    next_year = (i % 100) + 1\n",
    "    season_string = f\"{current_year:02d}_{next_year:02d}.csv\"\n",
    "    season_string_with_slash = '/' + season_string  # Add a \"/\" at the beginning\n",
    "    season_files.append(season_string_with_slash)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66196aa4",
   "metadata": {},
   "source": [
    "# Importing .csv Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f18687b2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9c/mcccghjd0j523rgfwsn1ldnm0000gn/T/ipykernel_59336/3268038154.py:11: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  dataframes[dataframe_name] = pd.read_csv(csv_path, encoding = \"utf-8\", error_bad_lines = False)\n",
      "/var/folders/9c/mcccghjd0j523rgfwsn1ldnm0000gn/T/ipykernel_59336/3268038154.py:11: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  dataframes[dataframe_name] = pd.read_csv(csv_path, encoding = \"utf-8\", error_bad_lines = False)\n",
      "/var/folders/9c/mcccghjd0j523rgfwsn1ldnm0000gn/T/ipykernel_59336/3268038154.py:11: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  dataframes[dataframe_name] = pd.read_csv(csv_path, encoding = \"utf-8\", error_bad_lines = False)\n",
      "/var/folders/9c/mcccghjd0j523rgfwsn1ldnm0000gn/T/ipykernel_59336/3268038154.py:11: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  dataframes[dataframe_name] = pd.read_csv(csv_path, encoding = \"utf-8\", error_bad_lines = False)\n",
      "Skipping line 305: expected 57 fields, saw 72\n",
      "Skipping line 306: expected 57 fields, saw 72\n",
      "Skipping line 307: expected 57 fields, saw 72\n",
      "Skipping line 308: expected 57 fields, saw 72\n",
      "Skipping line 309: expected 57 fields, saw 72\n",
      "Skipping line 310: expected 57 fields, saw 72\n",
      "Skipping line 311: expected 57 fields, saw 72\n",
      "Skipping line 312: expected 57 fields, saw 72\n",
      "Skipping line 313: expected 57 fields, saw 72\n",
      "Skipping line 314: expected 57 fields, saw 72\n",
      "Skipping line 315: expected 57 fields, saw 72\n",
      "Skipping line 316: expected 57 fields, saw 72\n",
      "Skipping line 317: expected 57 fields, saw 72\n",
      "Skipping line 318: expected 57 fields, saw 72\n",
      "Skipping line 319: expected 57 fields, saw 72\n",
      "Skipping line 320: expected 57 fields, saw 72\n",
      "Skipping line 321: expected 57 fields, saw 72\n",
      "Skipping line 322: expected 57 fields, saw 72\n",
      "Skipping line 323: expected 57 fields, saw 72\n",
      "Skipping line 324: expected 57 fields, saw 72\n",
      "Skipping line 325: expected 57 fields, saw 72\n",
      "Skipping line 326: expected 57 fields, saw 72\n",
      "Skipping line 327: expected 57 fields, saw 72\n",
      "Skipping line 328: expected 57 fields, saw 72\n",
      "Skipping line 329: expected 57 fields, saw 72\n",
      "Skipping line 330: expected 57 fields, saw 72\n",
      "Skipping line 331: expected 57 fields, saw 72\n",
      "Skipping line 332: expected 57 fields, saw 72\n",
      "Skipping line 333: expected 57 fields, saw 72\n",
      "Skipping line 334: expected 57 fields, saw 72\n",
      "Skipping line 335: expected 57 fields, saw 72\n",
      "Skipping line 336: expected 57 fields, saw 72\n",
      "Skipping line 369: expected 57 fields, saw 62\n",
      "Skipping line 370: expected 57 fields, saw 62\n",
      "Skipping line 371: expected 57 fields, saw 62\n",
      "Skipping line 372: expected 57 fields, saw 62\n",
      "Skipping line 373: expected 57 fields, saw 62\n",
      "Skipping line 374: expected 57 fields, saw 62\n",
      "Skipping line 375: expected 57 fields, saw 62\n",
      "Skipping line 376: expected 57 fields, saw 62\n",
      "Skipping line 377: expected 57 fields, saw 62\n",
      "Skipping line 378: expected 57 fields, saw 62\n",
      "Skipping line 379: expected 57 fields, saw 62\n",
      "Skipping line 380: expected 57 fields, saw 62\n",
      "Skipping line 381: expected 57 fields, saw 62\n",
      "\n",
      "/var/folders/9c/mcccghjd0j523rgfwsn1ldnm0000gn/T/ipykernel_59336/3268038154.py:11: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  dataframes[dataframe_name] = pd.read_csv(csv_path, encoding = \"utf-8\", error_bad_lines = False)\n",
      "/var/folders/9c/mcccghjd0j523rgfwsn1ldnm0000gn/T/ipykernel_59336/3268038154.py:11: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  dataframes[dataframe_name] = pd.read_csv(csv_path, encoding = \"utf-8\", error_bad_lines = False)\n",
      "/var/folders/9c/mcccghjd0j523rgfwsn1ldnm0000gn/T/ipykernel_59336/3268038154.py:11: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  dataframes[dataframe_name] = pd.read_csv(csv_path, encoding = \"utf-8\", error_bad_lines = False)\n",
      "/var/folders/9c/mcccghjd0j523rgfwsn1ldnm0000gn/T/ipykernel_59336/3268038154.py:11: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  dataframes[dataframe_name] = pd.read_csv(csv_path, encoding = \"utf-8\", error_bad_lines = False)\n",
      "/var/folders/9c/mcccghjd0j523rgfwsn1ldnm0000gn/T/ipykernel_59336/3268038154.py:11: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  dataframes[dataframe_name] = pd.read_csv(csv_path, encoding = \"utf-8\", error_bad_lines = False)\n",
      "/var/folders/9c/mcccghjd0j523rgfwsn1ldnm0000gn/T/ipykernel_59336/3268038154.py:11: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  dataframes[dataframe_name] = pd.read_csv(csv_path, encoding = \"utf-8\", error_bad_lines = False)\n",
      "/var/folders/9c/mcccghjd0j523rgfwsn1ldnm0000gn/T/ipykernel_59336/3268038154.py:11: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  dataframes[dataframe_name] = pd.read_csv(csv_path, encoding = \"utf-8\", error_bad_lines = False)\n",
      "/var/folders/9c/mcccghjd0j523rgfwsn1ldnm0000gn/T/ipykernel_59336/3268038154.py:11: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  dataframes[dataframe_name] = pd.read_csv(csv_path, encoding = \"utf-8\", error_bad_lines = False)\n",
      "/var/folders/9c/mcccghjd0j523rgfwsn1ldnm0000gn/T/ipykernel_59336/3268038154.py:11: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  dataframes[dataframe_name] = pd.read_csv(csv_path, encoding = \"utf-8\", error_bad_lines = False)\n",
      "/var/folders/9c/mcccghjd0j523rgfwsn1ldnm0000gn/T/ipykernel_59336/3268038154.py:11: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  dataframes[dataframe_name] = pd.read_csv(csv_path, encoding = \"utf-8\", error_bad_lines = False)\n",
      "/var/folders/9c/mcccghjd0j523rgfwsn1ldnm0000gn/T/ipykernel_59336/3268038154.py:11: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  dataframes[dataframe_name] = pd.read_csv(csv_path, encoding = \"utf-8\", error_bad_lines = False)\n",
      "/var/folders/9c/mcccghjd0j523rgfwsn1ldnm0000gn/T/ipykernel_59336/3268038154.py:11: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  dataframes[dataframe_name] = pd.read_csv(csv_path, encoding = \"utf-8\", error_bad_lines = False)\n",
      "/var/folders/9c/mcccghjd0j523rgfwsn1ldnm0000gn/T/ipykernel_59336/3268038154.py:11: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  dataframes[dataframe_name] = pd.read_csv(csv_path, encoding = \"utf-8\", error_bad_lines = False)\n",
      "/var/folders/9c/mcccghjd0j523rgfwsn1ldnm0000gn/T/ipykernel_59336/3268038154.py:11: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  dataframes[dataframe_name] = pd.read_csv(csv_path, encoding = \"utf-8\", error_bad_lines = False)\n",
      "/var/folders/9c/mcccghjd0j523rgfwsn1ldnm0000gn/T/ipykernel_59336/3268038154.py:11: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  dataframes[dataframe_name] = pd.read_csv(csv_path, encoding = \"utf-8\", error_bad_lines = False)\n",
      "/var/folders/9c/mcccghjd0j523rgfwsn1ldnm0000gn/T/ipykernel_59336/3268038154.py:11: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  dataframes[dataframe_name] = pd.read_csv(csv_path, encoding = \"utf-8\", error_bad_lines = False)\n",
      "/var/folders/9c/mcccghjd0j523rgfwsn1ldnm0000gn/T/ipykernel_59336/3268038154.py:11: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  dataframes[dataframe_name] = pd.read_csv(csv_path, encoding = \"utf-8\", error_bad_lines = False)\n",
      "/var/folders/9c/mcccghjd0j523rgfwsn1ldnm0000gn/T/ipykernel_59336/3268038154.py:11: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  dataframes[dataframe_name] = pd.read_csv(csv_path, encoding = \"utf-8\", error_bad_lines = False)\n",
      "/var/folders/9c/mcccghjd0j523rgfwsn1ldnm0000gn/T/ipykernel_59336/3268038154.py:11: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  dataframes[dataframe_name] = pd.read_csv(csv_path, encoding = \"utf-8\", error_bad_lines = False)\n"
     ]
    }
   ],
   "source": [
    "dataframes = {}\n",
    "\n",
    "base_path = r\"/Volumes/Ultra Touch/CofC MATH 540 EPL Project/Datasets\" #.csv files stored on external hard drive\n",
    "\n",
    "for i in season_files:\n",
    "    path_end = i\n",
    "    csv_path = base_path + path_end\n",
    "    \n",
    "    try:\n",
    "        dataframe_name = os.path.basename(i).split('.')[0]\n",
    "        dataframes[dataframe_name] = pd.read_csv(csv_path, encoding = \"utf-8\", error_bad_lines = False)\n",
    "    \n",
    "    except pd.errors.ParserError as e:\n",
    "            print(f\"Error reading CSV file: {i}\\nError message: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86882b34",
   "metadata": {},
   "source": [
    "# Editing Columns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03eb5e7a",
   "metadata": {},
   "source": [
    "### Drop Betting Statistic Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f4a67c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_columns_to_keep = [\"Date\", \"HomeTeam\", \"AwayTeam\", \"FTR\", \"HTHG\", \"HTAG\", \"HTR\", \"Referee\", \"HS\", \"AS\", \"HST\", \"AST\", \"HC\", \"AC\", \"HF\", \"AF\", \"HY\", \"AY\", \"HR\", \"AR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a6bd29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in dataframes.items():\n",
    "    dataframes[key] = df[final_columns_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538fd9a2",
   "metadata": {},
   "source": [
    "### Convert \"Referee\" Values to Last Name Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b5849cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataframes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataframes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m01_02\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataframes' is not defined"
     ]
    }
   ],
   "source": [
    "dataframes['01_02']\n",
    "# Formatting in 01_02 data frame is unique, so needs special attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4e17246",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = dataframes['01_02']['Referee'].str.contains(',')\n",
    "\n",
    "# Split and rearrange names for entries in 'LastName, FirstName' format\n",
    "dataframes['01_02'].loc[mask, 'Referee'] = dataframes['01_02'].loc[mask, 'Referee'].str.split(', ').apply(lambda x: f'{x[1]} {x[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d38c8f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in dataframes.items():\n",
    "    df['Referee'] = df['Referee'].str.split(' ').str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57c12069",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes['01_02'] = dataframes['01_02'][dataframes['01_02'][\"Referee\"] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "befd81bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Name: 00_01\n",
      "Referees: ['Harris' 'Barber' 'Knight' \"D'Urso\" 'Gallagher' 'Riley' 'Durkin' 'Dunn'\n",
      " 'Wiley' 'Lodge' 'Poll' 'Halsey' 'Winter' 'Jones' 'Hall' 'Ellaray'\n",
      " 'Taylor' 'Styles' 'Bennett' 'Barry' 'Dean' 'Burton' 'Messias' 'Wilkes' '']\n",
      "DataFrame Name: 01_02\n",
      "Referees: ['Barry' 'Durkin' 'Styles' 'Winter' 'Barber' 'Poll' 'Gallagher' 'Bennett'\n",
      " 'Rennie' 'Dean' 'Wilkes' 'Knight' \"D'Urso\" 'Wiley' 'Pugh' 'Riley'\n",
      " 'Halsey' 'Dunn' 'Wolstenholme' 'Jones' 'Elleray' 'Messias' 'Dowd' 'Foy'\n",
      " 'Yates']\n",
      "DataFrame Name: 02_03\n",
      "Referees: ['Elleray' 'Barber' 'Barry' 'Wiley' 'Poll' 'Bennett' 'Knight' 'Riley'\n",
      " \"D'Urso\" 'Durkin' 'Gallagher' 'Messias' 'Winter' 'Rennie' 'Dean' 'Styles'\n",
      " 'Wilkes' 'Dunn' 'Pugh' 'Wolstenholme' 'Halsey' 'Foy' 'Dowd']\n",
      "DataFrame Name: 03_04\n",
      "Referees: ['Halsey' 'Styles' 'Winter' 'Poll' 'Riley' 'Durkin' 'Barber' 'Dean'\n",
      " 'Martin' 'Bennett' \"D'Urso\" 'Barry' 'Messias' 'Rennie' 'Dunn' 'Dowd'\n",
      " 'Gallagher' 'Wiley' 'Foy' 'Knight' 'Webb' 'Walton']\n",
      "DataFrame Name: 04_05\n",
      "Referees: ['Rennie' 'Foy' 'Dowd' 'Messias' 'Bennett' 'Walton' 'Webb' 'Gallagher'\n",
      " 'Poll' 'Riley' 'Knight' 'Wiley' 'Clattenburg' 'Styles' 'Barry' 'Dean'\n",
      " \"D'Urso\" 'Dunn' 'Halsey' 'Atkinson' 'Crossley' 'Marriner' 'Beeby']\n",
      "DataFrame Name: 05_06\n",
      "Referees: ['Riley' 'Poll' 'Styles' 'Foy' 'Halsey' 'Knight' 'Webb' 'Wiley' 'Bennett'\n",
      " 'Clattenburg' 'Dowd' 'Gallagher' 'Atkinson' 'Walton' 'Dean' 'Beeby'\n",
      " 'Rennie' 'Marriner' \"D'Urso\" 'Williamson' 'Mason' 'Stroud']\n",
      "DataFrame Name: 06_07\n",
      "Referees: ['Poll' 'Dowd' 'Walton' 'Atkinson' 'Wiley' 'Halsey' 'Styles' 'Webb'\n",
      " 'Bennett' 'Marriner' 'Mason' 'Rennie' 'Foy' 'Gallagher' 'Dean' 'Riley'\n",
      " 'Clattenburg' 'Tanner' 'Probert' 'Stroud' 'Gallagh' 'Gallaghe']\n",
      "DataFrame Name: 07_08\n",
      "Referees: ['Riley' 'Foy' 'Dean' 'Clattenburg' 'Marriner' 'Wiley' 'Walton' 'Dowd'\n",
      " 'Bennett' 'Styles' 'Halsey' 'Stroud' 'Probert' 'Mason' 'Tanner' 'Webb'\n",
      " 'Atkinson' 'Rennie']\n",
      "DataFrame Name: 08_09\n",
      "Referees: ['Webb' 'Foy' 'Marriner' 'Walton' 'Atkinson' 'Wiley' 'Bennett' 'Dowd'\n",
      " 'Dean' 'Riley' 'Attwell' 'Halsey' 'Styles' 'Stroud' 'Jones' 'Tanner'\n",
      " 'Probert' 'Mason' 'Clattenburg']\n",
      "DataFrame Name: 09_10\n",
      "Referees: ['Clattenburg' 'Dean' 'Marriner' 'Wiley' 'Halsey' 'Atkinson' 'Bennett'\n",
      " 'Foy' 'Mason' 'Dowd' 'Jones' 'Probert' 'Walton' 'Webb' 'Attwell' 'Friend'\n",
      " 'Taylor']\n",
      "DataFrame Name: 10_11\n",
      "Referees: ['Dean' 'Dowd' 'Attwell' 'Clattenburg' 'Taylor' 'Marriner' 'Halsey'\n",
      " 'Probert' 'Atkinson' 'Foy' 'Jones' 'Oliver' 'Mason' 'Friend' 'Walton'\n",
      " 'Webb' 'Swarbrick' 'Moss']\n",
      "DataFrame Name: 11_12\n",
      "Referees: ['Friend' 'Mason' 'Dowd' 'Walton' 'Atkinson' 'Attwell' 'Halsey' 'Jones'\n",
      " 'Dean' 'Webb' 'Swarbrick' 'Probert' 'Oliver' 'Marriner' 'Clattenburg'\n",
      " 'Taylor' 'Moss' 'Foy']\n",
      "DataFrame Name: 12_13\n",
      "Referees: ['Foy' 'Oliver' 'Atkinson' 'Probert' 'Friend' 'Dowd' 'Dean' 'Webb' 'Jones'\n",
      " 'Marriner' 'Mason' 'Clattenburg' 'Taylor' 'East' 'Halsey' 'Moss'\n",
      " 'Swarbrick' 'Pawson' 'Madley']\n",
      "DataFrame Name: 13_14\n",
      "Referees: ['Taylor' 'Atkinson' 'Oliver' 'Swarbrick' 'Dowd' 'Friend' 'Webb' 'Moss'\n",
      " 'Clattenburg' 'Marriner' 'East' 'Jones' 'Mason' 'Probert' 'Foy' 'Dean'\n",
      " 'Madley' 'Pawson']\n",
      "DataFrame Name: 14_15\n",
      "Referees: ['Moss' 'Jones' 'Dean' 'Pawson' 'Taylor' 'Swarbrick' 'Foy' 'Clattenburg'\n",
      " 'Atkinson' 'Oliver' 'Mason' 'Friend' 'East' 'Madley' 'Tierney' 'Dowd'\n",
      " 'Stroud' 'Marriner' 'Attwell' 'Scott' 'Probert' nan]\n",
      "DataFrame Name: 15_16\n",
      "Referees: ['Clattenburg' 'Oliver' 'Jones' 'Mason' 'Moss' 'Hooper' 'Atkinson'\n",
      " 'Pawson' 'Taylor' 'Dean' 'Friend' 'Madley' 'Tierney' 'Stroud' 'Swarbrick'\n",
      " 'Marriner' 'Attwell' 'East' 'Scott']\n",
      "DataFrame Name: 16_17\n",
      "Referees: ['Moss' 'Pawson' 'Atkinson' 'Dean' 'Madley' 'Friend' 'East' 'Oliver'\n",
      " 'Marriner' 'Taylor' 'Mason' 'Clattenburg' 'Attwell' 'Swarbrick' 'Tierney'\n",
      " 'Jones' 'Scott' 'Probert' 'Kavanagh']\n",
      "DataFrame Name: 17_18\n",
      "Referees: ['Dean' 'Oliver' 'Pawson' 'Moss' 'Swarbrick' 'Jones' 'Taylor' 'Madley'\n",
      " 'Atkinson' 'Marriner' 'East' 'Probert' 'Friend' 'Mason' 'Attwell' 'Scott'\n",
      " 'Kavanagh' 'Tierney' 'Hooper' 'Coote']\n",
      "DataFrame Name: 18_19\n",
      "Referees: ['Marriner' 'Friend' 'Dean' 'Kavanagh' 'Atkinson' 'Moss' 'Pawson' 'Oliver'\n",
      " 'Taylor' 'Scott' 'Mason' 'Attwell' 'Tierney' 'Probert' 'Coote' 'East'\n",
      " 'Hooper' 'Madley']\n",
      "DataFrame Name: 19_20\n",
      "Referees: ['Oliver' 'Dean' 'Friend' 'Scott' 'Moss' 'Pawson' 'Kavanagh' 'Marriner'\n",
      " 'Atkinson' 'Taylor' 'Mason' 'Attwell' 'Coote' 'Langford' 'Tierney'\n",
      " 'Madley' 'Bankes' 'Hooper' 'Robinson' 'Jones' 'England']\n",
      "DataFrame Name: 20_21\n",
      "Referees: ['Kavanagh' 'Moss' 'Oliver' 'Attwell' 'Taylor' 'Atkinson' 'Pawson' 'Dean'\n",
      " 'Coote' 'Friend' 'Tierney' 'Mason' 'Scott' 'Marriner' 'Bankes' 'Hooper'\n",
      " 'Madley' 'England' 'Jones']\n",
      "DataFrame Name: 21_22\n",
      "Referees: ['Oliver' 'Tierney' 'Coote' 'Moss' 'Madley' 'Pawson' 'Dean' 'Marriner'\n",
      " 'Atkinson' 'Taylor' 'England' 'Scott' 'Attwell' 'Bankes' 'Jones' 'Friend'\n",
      " 'Kavanagh' 'Gillett' 'Hooper' 'Salisbury' 'Brooks' 'Harrington']\n",
      "DataFrame Name: 22_23\n",
      "Referees: ['Taylor' 'Madley' 'Bankes' 'Jones' 'Hooper' 'Marriner' 'Pawson' 'Gillett'\n",
      " 'Tierney' 'Oliver' 'England' 'Scott' 'Coote' 'Harrington' 'Brooks'\n",
      " 'Attwell' 'Salisbury' 'Bramall' 'Kavanagh' 'Bond' 'Robinson' 'Smith']\n"
     ]
    }
   ],
   "source": [
    "for key, df in dataframes.items():\n",
    "    print(f\"DataFrame Name: {key}\")\n",
    "    print(\"Referees:\", df[\"Referee\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46479ad4",
   "metadata": {},
   "source": [
    "### Standardize \"Date\" Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80069a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9c/mcccghjd0j523rgfwsn1ldnm0000gn/T/ipykernel_59336/1132233030.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Date'] = df['Date'].astype(str)\n",
      "/var/folders/9c/mcccghjd0j523rgfwsn1ldnm0000gn/T/ipykernel_59336/1132233030.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Date'] = df['Date'].apply(convert_to_standard_format)\n"
     ]
    }
   ],
   "source": [
    "for key, df in dataframes.items():\n",
    "    # Convert the \"Date\" column to string to handle different formats\n",
    "    df['Date'] = df['Date'].astype(str)\n",
    "\n",
    "    # Define a function to convert the \"Date\" value to the standard format DD/MM/YY\n",
    "    def convert_to_standard_format(date_str):\n",
    "        try:\n",
    "            date_obj = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "            return date_obj.strftime('%d/%m/%y')\n",
    "        except ValueError:\n",
    "            try:\n",
    "                # Attempt to parse with a different format\n",
    "                date_obj = pd.to_datetime(date_str, format='%d/%m/%y')\n",
    "                # Handle cases where the year is ambiguous (adjust this part as needed)\n",
    "                if date_obj.year <= 99:\n",
    "                    return date_obj.replace(year=date_obj.year + 2000).strftime('%d/%m/%y')\n",
    "                return date_obj.strftime('%d/%m/%y')\n",
    "            except ValueError:\n",
    "                # Handle other cases, or leave them as is\n",
    "                return date_str\n",
    "        \n",
    "    # Apply the conversion function to the \"Date\" column\n",
    "    df['Date'] = df['Date'].apply(convert_to_standard_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329958c3",
   "metadata": {},
   "source": [
    "### Create \"Day\" Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3802af81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9c/mcccghjd0j523rgfwsn1ldnm0000gn/T/ipykernel_59336/280372817.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%y')\n",
      "/var/folders/9c/mcccghjd0j523rgfwsn1ldnm0000gn/T/ipykernel_59336/280372817.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Day'] = df['Date'].dt.strftime(\"%A\")\n"
     ]
    }
   ],
   "source": [
    "for key, df in dataframes.items():\n",
    "    # Convert the \"Date\" column to datetime format\n",
    "    df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%y')\n",
    "\n",
    "    # Create the \"Day\" column containing the day of the week as a string\n",
    "    df['Day'] = df['Date'].dt.strftime(\"%A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b51e3c",
   "metadata": {},
   "source": [
    "### Create \"Month\" Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "114eabbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9c/mcccghjd0j523rgfwsn1ldnm0000gn/T/ipykernel_59336/1616367450.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%y')\n",
      "/var/folders/9c/mcccghjd0j523rgfwsn1ldnm0000gn/T/ipykernel_59336/1616367450.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Month'] = df['Date'].dt.strftime(\"%B\")\n"
     ]
    }
   ],
   "source": [
    "for key, df in dataframes.items():\n",
    "    # Ensure the \"Date\" column is in datetime format\n",
    "    df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%y')\n",
    "    \n",
    "    # Create the \"Month\" column containing the corresponding month as a full name string\n",
    "    df['Month'] = df['Date'].dt.strftime(\"%B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c466c17d",
   "metadata": {},
   "source": [
    "### Convert \"FTR\" (Response) to Binary Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f39563fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9c/mcccghjd0j523rgfwsn1ldnm0000gn/T/ipykernel_59336/1005186426.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['FTR'] = df['FTR'].replace({'H': 1, 'D': 0, 'A': 0})\n"
     ]
    }
   ],
   "source": [
    "for key, df in dataframes.items():\n",
    "    df['FTR'] = df['FTR'].replace({'H': 1, 'D': 0, 'A': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059346c2",
   "metadata": {},
   "source": [
    "# Create COVID Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8ffa43",
   "metadata": {},
   "source": [
    "### \"Date\" Range = 2020-06-17 to 2021-05-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a87f46f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9c/mcccghjd0j523rgfwsn1ldnm0000gn/T/ipykernel_59336/3780378064.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Date'] = pd.to_datetime(df['Date'])\n"
     ]
    }
   ],
   "source": [
    "COVID_df = pd.DataFrame()\n",
    "\n",
    "# Define the start and end dates for the desired date range\n",
    "start_date = '2020-06-17'\n",
    "end_date = '2021-05-16'\n",
    "\n",
    "# Assuming dataframes is a dictionary of your 23 DataFrames\n",
    "dfs_to_concat = []  # Create a list to hold filtered DataFrames\n",
    "\n",
    "for key, df in dataframes.items():\n",
    "    # Ensure the \"Date\" column is in datetime format\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "    # Filter each DataFrame within the date range\n",
    "    date_range_mask = (df['Date'] >= start_date) & (df['Date'] <= end_date)\n",
    "    filtered_df = df[date_range_mask]\n",
    "\n",
    "    # Append the filtered DataFrame to the list\n",
    "    dfs_to_concat.append(filtered_df)\n",
    "\n",
    "# Concatenate the list of DataFrames into a single combined DataFrame\n",
    "COVID_df = pd.concat(dfs_to_concat, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1d2e6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>HTR</th>\n",
       "      <th>Referee</th>\n",
       "      <th>HS</th>\n",
       "      <th>AS</th>\n",
       "      <th>...</th>\n",
       "      <th>HC</th>\n",
       "      <th>AC</th>\n",
       "      <th>HF</th>\n",
       "      <th>AF</th>\n",
       "      <th>HY</th>\n",
       "      <th>AY</th>\n",
       "      <th>HR</th>\n",
       "      <th>AR</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-17</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>Sheffield United</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>Oliver</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>June</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-06-17</td>\n",
       "      <td>Man City</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>Taylor</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>June</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-06-19</td>\n",
       "      <td>Norwich</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>Friend</td>\n",
       "      <td>9.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>June</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-06-19</td>\n",
       "      <td>Tottenham</td>\n",
       "      <td>Man United</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>Moss</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>June</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-06-20</td>\n",
       "      <td>Watford</td>\n",
       "      <td>Leicester</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>Pawson</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>June</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>2021-05-15</td>\n",
       "      <td>Brighton</td>\n",
       "      <td>West Ham</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>Marriner</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>May</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>2021-05-16</td>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A</td>\n",
       "      <td>Coote</td>\n",
       "      <td>23.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>May</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>2021-05-16</td>\n",
       "      <td>Tottenham</td>\n",
       "      <td>Wolves</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>Atkinson</td>\n",
       "      <td>24.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>May</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>2021-05-16</td>\n",
       "      <td>West Brom</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>D</td>\n",
       "      <td>Dean</td>\n",
       "      <td>10.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>May</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>2021-05-16</td>\n",
       "      <td>Everton</td>\n",
       "      <td>Sheffield United</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>Moss</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>May</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>452 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date        HomeTeam          AwayTeam  FTR  HTHG  HTAG HTR  \\\n",
       "0   2020-06-17     Aston Villa  Sheffield United  0.0   0.0   0.0   D   \n",
       "1   2020-06-17        Man City           Arsenal  1.0   1.0   0.0   H   \n",
       "2   2020-06-19         Norwich       Southampton  0.0   0.0   0.0   D   \n",
       "3   2020-06-19       Tottenham        Man United  0.0   1.0   0.0   H   \n",
       "4   2020-06-20         Watford         Leicester  0.0   0.0   0.0   D   \n",
       "..         ...             ...               ...  ...   ...   ...  ..   \n",
       "447 2021-05-15        Brighton          West Ham  0.0   0.0   0.0   D   \n",
       "448 2021-05-16  Crystal Palace       Aston Villa  1.0   1.0   2.0   A   \n",
       "449 2021-05-16       Tottenham            Wolves  1.0   1.0   0.0   H   \n",
       "450 2021-05-16       West Brom         Liverpool  0.0   1.0   1.0   D   \n",
       "451 2021-05-16         Everton  Sheffield United  0.0   0.0   1.0   A   \n",
       "\n",
       "      Referee    HS    AS  ...    HC    AC    HF    AF   HY   AY   HR   AR  \\\n",
       "0      Oliver  14.0   5.0  ...  12.0   4.0  11.0  14.0  1.0  1.0  0.0  0.0   \n",
       "1      Taylor  20.0   3.0  ...   5.0   2.0   9.0   7.0  1.0  1.0  0.0  1.0   \n",
       "2      Friend   9.0  22.0  ...   9.0   7.0   9.0  15.0  1.0  1.0  0.0  0.0   \n",
       "3        Moss  10.0  12.0  ...   7.0   6.0  17.0  18.0  0.0  1.0  0.0  0.0   \n",
       "4      Pawson   8.0  15.0  ...   2.0   7.0  15.0  12.0  0.0  1.0  0.0  0.0   \n",
       "..        ...   ...   ...  ...   ...   ...   ...   ...  ...  ...  ...  ...   \n",
       "447  Marriner  10.0  15.0  ...   3.0   3.0   7.0   5.0  1.0  1.0  0.0  0.0   \n",
       "448     Coote  23.0  19.0  ...   7.0   7.0  23.0  13.0  3.0  2.0  0.0  0.0   \n",
       "449  Atkinson  24.0  15.0  ...  10.0   3.0   8.0  11.0  1.0  0.0  0.0  0.0   \n",
       "450      Dean  10.0  26.0  ...   9.0  13.0   7.0  14.0  0.0  0.0  0.0  0.0   \n",
       "451      Moss  16.0  10.0  ...  11.0   4.0   8.0  12.0  1.0  3.0  0.0  0.0   \n",
       "\n",
       "           Day  Month  \n",
       "0    Wednesday   June  \n",
       "1    Wednesday   June  \n",
       "2       Friday   June  \n",
       "3       Friday   June  \n",
       "4     Saturday   June  \n",
       "..         ...    ...  \n",
       "447   Saturday    May  \n",
       "448     Sunday    May  \n",
       "449     Sunday    May  \n",
       "450     Sunday    May  \n",
       "451     Sunday    May  \n",
       "\n",
       "[452 rows x 22 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COVID_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a204f25",
   "metadata": {},
   "source": [
    "### Remove COVID Test Set Rows from 'dataframes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2974c758",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9c/mcccghjd0j523rgfwsn1ldnm0000gn/T/ipykernel_59336/1951959242.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Date'] = pd.to_datetime(df['Date'])\n"
     ]
    }
   ],
   "source": [
    "start_date = '2020-06-17'\n",
    "end_date = '2021-05-16'\n",
    "\n",
    "# Create a dictionary to store the filtered DataFrames\n",
    "filtered_dataframes = {}\n",
    "\n",
    "# Assuming dataframes is a dictionary of your 23 DataFrames\n",
    "for key, df in dataframes.items():\n",
    "    # Ensure the \"Date\" column is in datetime format\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "    # Create a boolean mask to select rows outside the date range\n",
    "    date_range_mask = (df['Date'] < start_date) | (df['Date'] > end_date)\n",
    "\n",
    "    # Filter the DataFrame to retain only the rows outside the date range\n",
    "    filtered_df = df[date_range_mask]\n",
    "\n",
    "    # Store the filtered DataFrame in the new dictionary\n",
    "    filtered_dataframes[key] = filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01060df",
   "metadata": {},
   "source": [
    "# Export Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65b006db",
   "metadata": {},
   "outputs": [],
   "source": [
    "COVID_df.to_csv(\"/Volumes/Ultra Touch/CofC MATH 540 EPL Project/Clean Data/COVID.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42def847",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_path = '/Volumes/Ultra Touch/CofC MATH 540 EPL Project/Clean Data/'  \n",
    "\n",
    "for key, df in filtered_dataframes.items():\n",
    "    # Construct the full path for the CSV file using the key\n",
    "    csv_filename = f\"{export_path}{key}.csv\"\n",
    "\n",
    "    # Export the DataFrame as a CSV file with the specified name\n",
    "    df.to_csv(csv_filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
